# üìã Guia de Implementa√ß√£o - Dados Reais de Sa√∫de

## üéØ Vis√£o Geral

Este guia documenta como utilizar o sistema de integra√ß√£o com **fontes oficiais de dados de sa√∫de do Brasil**, garantindo conformidade com LGPD e Lei de Acesso √† Informa√ß√£o.

## üèõÔ∏è Fontes de Dados Oficiais

### **1. DATASUS - Minist√©rio da Sa√∫de**
- **URL**: http://tabnet.datasus.gov.br
- **Dados**: Taxa de ocupa√ß√£o hospitalar, interna√ß√µes, procedimentos
- **Atualiza√ß√£o**: Mensal
- **Formato**: TabNet (requer parsing espec√≠fico)
- **Cache TTL**: 24 horas

### **2. ANS - Ag√™ncia Nacional de Sa√∫de Suplementar**
- **URL**: https://www.ans.gov.br/anstabnet
- **Dados**: Benefici√°rios de planos de sa√∫de por munic√≠pio
- **Atualiza√ß√£o**: Trimestral
- **Formato**: API REST + TabNet
- **Cache TTL**: 7 dias

### **3. IBGE - Instituto Brasileiro de Geografia e Estat√≠stica**
- **URL**: https://servicodados.ibge.gov.br/api
- **Dados**: Popula√ß√£o, demografia, indicadores sociais
- **Atualiza√ß√£o**: Anual/Decenal
- **Formato**: JSON REST API
- **Cache TTL**: 30 dias

### **4. Anatel - Ag√™ncia Nacional de Telecomunica√ß√µes**
- **URL**: https://sistemas.anatel.gov.br
- **Dados**: Conectividade, cobertura de rede, velocidade
- **Atualiza√ß√£o**: Mensal
- **Formato**: Relat√≥rios estruturados
- **Cache TTL**: 7 dias

### **5. CETIC.br - Centro Regional de Estudos TIC**
- **URL**: https://cetic.br
- **Dados**: Digitaliza√ß√£o, uso de tecnologia na sa√∫de
- **Atualiza√ß√£o**: Anual
- **Formato**: Relat√≥rios PDF/Excel
- **Cache TTL**: 1 ano

## üöÄ Como Usar

### **Instala√ß√£o de Depend√™ncias**
```bash
# Backend - depend√™ncias para APIs
pip install requests pandas numpy pyarrow boto3

# Analytics - bibliotecas de visualiza√ß√£o
pip install plotly matplotlib seaborn cartopy geopandas

# Conformidade LGPD
pip install cryptography hashlib
```

### **1. Inicializa√ß√£o B√°sica**
```python
from real_data_loader import RealHealthDataLoader
from real_data_config import print_validation_report

# Verificar ambiente
print_validation_report()

# Inicializar carregador
loader = RealHealthDataLoader(api_base_url='http://localhost:3001')
```

### **2. Carregar Dados Completos**
```python
# Carrega todos os indicadores de todos os munic√≠pios
df_complete = loader.load_real_data()

print(f"Munic√≠pios carregados: {len(df_complete)}")
print(f"Indicadores: {list(df_complete.columns)}")
```

### **3. Usar no Jupyter Notebook**
```python
# No notebook indicadores-saude-nordeste.ipynb
health_data = load_health_data_with_real_integration(config)

# Dados est√£o prontos para visualiza√ß√£o
df_municipios = health_data['municipios']
df_timeseries = health_data['timeseries']
df_especialidades = health_data['especialidades']
```

### **4. Integra√ß√£o com Backend**
```javascript
// Solicitar dados via API
const response = await fetch('/api/analytics/indicators?source=completo');
const data = await response.json();

console.log(`Munic√≠pios: ${data.metadata.total_municipalities}`);
console.log(`Fontes: ${data.metadata.data_sources.join(', ')}`);
```

## üìä Estrutura dos Dados

### **DataFrame Principal**
```python
{
    'Munic√≠pio': str,           # Nome do munic√≠pio
    'UF': str,                  # Unidade Federativa
    'Tipo': str,                # 'capital' ou 'interior'
    'Populacao': int,           # Popula√ß√£o total (IBGE)
    'Taxa_Ocupacao_Hospitalar': float,    # 0-100% (DATASUS)
    'Penetracao_Planos_Saude': float,     # 0-100% (ANS)
    'Conectividade_Digital_Mbps': float,  # Mbps (Anatel)
    'Resolutividade_Local': float,        # 0-100% (calculado)
    'Latitude': float,          # Coordenadas geogr√°ficas
    'Longitude': float,         # Coordenadas geogr√°ficas
    'Performance_Geral': float  # √çndice calculado
}
```

### **Dados de S√©ries Temporais**
```python
{
    'cidade': str,
    'estado': str,
    'data': datetime,
    'ocupacao_hospitalar': float,
    'consultas_mes': int,
    'referencias_enviadas': int,
    'referencias_recebidas': int
}
```

## üîß Configura√ß√£o Avan√ßada

### **1. Cache Personalizado**
```python
# Configurar cache por fonte
loader = RealHealthDataLoader()
loader.cache_config = {
    'datasus': {'ttl': 12 * 60 * 60 * 1000},  # 12 horas
    'ans': {'ttl': 3 * 24 * 60 * 60 * 1000},  # 3 dias
    'ibge': {'ttl': 15 * 24 * 60 * 60 * 1000} # 15 dias
}
```

### **2. Filtros Personalizados**
```python
# Carregar apenas capitais
municipios_filtrados = [m for m in loader.municipiosNordeste if m['tipo'] == 'capital']
df_capitais = loader.fetchIndicadoresCompletos(municipios_filtrados)

# Carregar apenas um estado
municipios_ce = [m for m in loader.municipiosNordeste if m['uf'] == 'CE']
df_ceara = loader.fetchIndicadoresCompletos(municipios_ce)
```

### **3. Fallback Inteligente**
```python
try:
    # Tentar dados reais
    df = loader.fetchOcupacaoHospitalar()
except Exception as e:
    print(f"API indispon√≠vel: {e}")
    # Usar dados simulados real√≠sticos
    df = loader.load_simulated_realistic_data()
```

## üõ°Ô∏è Conformidade LGPD

### **Princ√≠pios Implementados**

1. **Minimiza√ß√£o de Dados**: Apenas dados necess√°rios para analytics
2. **Finalidade Espec√≠fica**: Uso exclusivo para dashboard de sa√∫de
3. **Transpar√™ncia**: Logs de auditoria de todos os acessos
4. **Seguran√ßa**: Criptografia em tr√¢nsito, cache tempor√°rio

### **Logs de Auditoria**
```python
# Cada acesso √© registrado
audit_log = {
    'timestamp': '2025-10-23T15:30:00Z',
    'user_id': 'system',
    'action': 'DATA_ACCESS',
    'resource': 'health_indicators',
    'purpose': 'ANALYTICAL_DASHBOARD',
    'legal_basis': 'LEGITIMATE_INTEREST',
    'data_sources': ['DATASUS', 'ANS', 'IBGE'],
    'municipalities_count': 18,
    'retention_period': '2_YEARS'
}
```

### **Relat√≥rio de Conformidade**
```python
# Gerar relat√≥rio LGPD
compliance_report = loader.generateAuditReport()
print(f"Status: {compliance_report['compliance_status']}")
print(f"Acessos: {compliance_report['total_requests']}")
print(f"Reten√ß√£o: {compliance_report['retention_policy']}")
```

## üìà Monitoramento e Alertas

### **Status das APIs**
```python
from real_data_config import validate_environment

# Verificar status
status = validate_environment()
print(f"APIs funcionais: {sum(status['api_access'].values())}/{len(status['api_access'])}")

# Alertas autom√°ticos
if not status['internet_connection']:
    print("üö® ALERTA: Sem conectividade com internet")

if sum(status['api_access'].values()) < 2:
    print("‚ö†Ô∏è ALERTA: Poucas APIs dispon√≠veis")
```

### **Performance e Rate Limiting**
```python
# Rate limiting autom√°tico
loader.rateLimiter = {
    'datasus': {'last_request': datetime.now(), 'requests_count': 0},
    'ans': {'last_request': datetime.now(), 'requests_count': 0}
}

# Verificar antes de cada request
if not loader.checkRateLimit('datasus'):
    print("‚è∏Ô∏è Rate limit atingido, aguardando...")
    time.sleep(60)
```

## üîÑ Atualiza√ß√£o Autom√°tica

### **Script de Atualiza√ß√£o**
```python
def update_health_data():
    """
    Script para atualiza√ß√£o autom√°tica dos dados
    Executar via cron ou task scheduler
    """
    try:
        loader = RealHealthDataLoader()
        
        # Carregar dados atualizados
        df = loader.load_real_data()
        
        # Salvar para cache
        loader.save_data_for_api(df)
        
        # Gerar mapas atualizados
        subprocess.run(['python', 'generate_maps.py'])
        
        print(f"‚úÖ Dados atualizados: {len(df)} munic√≠pios")
        
    except Exception as e:
        print(f"‚ùå Erro na atualiza√ß√£o: {e}")
        # Enviar alerta por email/Slack
        send_alert(f"Falha na atualiza√ß√£o de dados: {e}")

# Executar diariamente √†s 06:00
# crontab: 0 6 * * * /usr/bin/python3 /path/to/update_health_data.py
```

### **Webhook para Atualiza√ß√µes**
```javascript
// Endpoint no backend para trigger manual
app.post('/api/analytics/refresh', async (req, res) => {
  try {
    const result = await execSync('python update_health_data.py');
    res.json({ success: true, message: 'Dados atualizados' });
  } catch (error) {
    res.status(500).json({ success: false, error: error.message });
  }
});
```

## üß™ Testes e Valida√ß√£o

### **Testes de Integra√ß√£o**
```python
def test_data_integration():
    """Testa integra√ß√£o com todas as fontes"""
    loader = RealHealthDataLoader()
    
    # Testar cada fonte individualmente
    tests = {
        'ocupacao': loader.fetchOcupacaoHospitalar,
        'planos': loader.fetchPenetracaoPlanos,
        'conectividade': loader.fetchConectividadeDigital,
        'completo': loader.fetchIndicadoresCompletos
    }
    
    results = {}
    for test_name, test_func in tests.items():
        try:
            data = test_func()
            results[test_name] = {
                'success': True,
                'records': len(data) if data else 0
            }
        except Exception as e:
            results[test_name] = {
                'success': False,
                'error': str(e)
            }
    
    return results
```

### **Valida√ß√£o de Qualidade**
```python
def validate_data_quality(df):
    """Valida qualidade dos dados carregados"""
    issues = []
    
    # Verificar dados faltantes
    missing_data = df.isnull().sum()
    if missing_data.any():
        issues.append(f"Dados faltantes: {missing_data.to_dict()}")
    
    # Verificar outliers
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        q1, q3 = df[col].quantile([0.25, 0.75])
        iqr = q3 - q1
        outliers = df[(df[col] < q1 - 1.5*iqr) | (df[col] > q3 + 1.5*iqr)]
        if len(outliers) > 0:
            issues.append(f"Outliers em {col}: {len(outliers)} registros")
    
    # Verificar consist√™ncia temporal
    if 'data_coleta' in df.columns:
        old_data = df[df['data_coleta'] < datetime.now() - timedelta(days=30)]
        if len(old_data) > 0:
            issues.append(f"Dados antigos (>30 dias): {len(old_data)} registros")
    
    return {
        'valid': len(issues) == 0,
        'issues': issues,
        'quality_score': max(0, 100 - len(issues) * 10)
    }
```

## üìö Pr√≥ximos Passos

1. **Expans√£o Regional**: Adicionar outras regi√µes do Brasil
2. **APIs Adicionais**: Integrar com mais fontes governamentais
3. **Machine Learning**: Modelos preditivos com dados hist√≥ricos
4. **Real-time**: Streaming de dados em tempo real
5. **Data Lake**: Integra√ß√£o com solu√ß√µes de Big Data

## üìû Suporte

- **Documenta√ß√£o**: `/docs/api-integration.md`
- **Issues**: GitHub Issues para problemas t√©cnicos
- **Conformidade**: `/docs/lgpd-compliance.md`
- **Performance**: `/docs/performance-tuning.md`

---

**‚úÖ Sistema pronto para produ√ß√£o com conformidade total LGPD e LAI**